{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6bd2f49-ed1c-47a4-8766-b13d268486d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All datasets loaded!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set working directory\n",
    "data_dir = r\"E:\\Project + App\"\n",
    "\n",
    "# File names\n",
    "files = {\n",
    "    \"DEMO\": \"P_DEMO.XPT\",\n",
    "    \"GHB\": \"P_GHB.XPT\",\n",
    "    \"ALB_CR\": \"P_ALB_CR.XPT\",\n",
    "    \"MCQ\": \"P_MCQ.XPT\",\n",
    "    \"SMQ\": \"P_SMQ.XPT\",\n",
    "    \"PAQ\": \"P_PAQ.XPT\",\n",
    "    \"GLU\": \"P_GLU.XPT\"\n",
    "}\n",
    "\n",
    "# Load all files into a dictionary of DataFrames\n",
    "data = {}\n",
    "for key, fname in files.items():\n",
    "    fpath = os.path.join(data_dir, fname)\n",
    "    data[key] = pd.read_sas(fpath)\n",
    "\n",
    "print(\"âœ… All datasets loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519764a8-71d5-40aa-ab4e-6ea3eca58036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ DEMO: 15560 rows, 29 columns\n",
      "Index(['SEQN', 'SDDSRVYR', 'RIDSTATR', 'RIAGENDR', 'RIDAGEYR', 'RIDAGEMN',\n",
      "       'RIDRETH1', 'RIDRETH3', 'RIDEXMON', 'DMDBORN4'],\n",
      "      dtype='object')\n",
      "\n",
      "ðŸ”¹ GHB: 10409 rows, 2 columns\n",
      "Index(['SEQN', 'LBXGH'], dtype='object')\n",
      "\n",
      "ðŸ”¹ ALB_CR: 13027 rows, 8 columns\n",
      "Index(['SEQN', 'URXUMA', 'URXUMS', 'URDUMALC', 'URXUCR', 'URXCRS', 'URDUCRLC',\n",
      "       'URDACT'],\n",
      "      dtype='object')\n",
      "\n",
      "ðŸ”¹ MCQ: 14986 rows, 63 columns\n",
      "Index(['SEQN', 'MCQ010', 'MCQ025', 'MCQ035', 'MCQ040', 'MCQ050', 'AGQ030',\n",
      "       'MCQ053', 'MCQ080', 'MCQ092'],\n",
      "      dtype='object')\n",
      "\n",
      "ðŸ”¹ SMQ: 11137 rows, 16 columns\n",
      "Index(['SEQN', 'SMQ020', 'SMD030', 'SMQ040', 'SMQ050Q', 'SMQ050U', 'SMD057',\n",
      "       'SMQ078', 'SMD641', 'SMD650'],\n",
      "      dtype='object')\n",
      "\n",
      "ðŸ”¹ PAQ: 9693 rows, 17 columns\n",
      "Index(['SEQN', 'PAQ605', 'PAQ610', 'PAD615', 'PAQ620', 'PAQ625', 'PAD630',\n",
      "       'PAQ635', 'PAQ640', 'PAD645'],\n",
      "      dtype='object')\n",
      "\n",
      "ðŸ”¹ GLU: 5090 rows, 4 columns\n",
      "Index(['SEQN', 'WTSAFPRP', 'LBXGLU', 'LBDGLUSI'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "for key, df in data.items():\n",
    "    print(f\"\\nðŸ”¹ {key}: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "    print(df.columns[:10])  # Show first 10 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4807b862-e209-4e79-bd39-e739b3e2476d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Merged dataset shape: (4438, 133)\n"
     ]
    }
   ],
   "source": [
    "# Start with DEMO as the base\n",
    "df = data['DEMO']\n",
    "\n",
    "# Merge each of the other files onto df\n",
    "merge_keys = ['GHB', 'ALB_CR', 'MCQ', 'SMQ', 'PAQ', 'GLU']\n",
    "\n",
    "for key in merge_keys:\n",
    "    df = pd.merge(df, data[key], on='SEQN', how='inner')\n",
    "\n",
    "print(f\"âœ… Merged dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77974f79-ab03-43c5-8abe-3c71f2ca2b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Final selected shape: (4438, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>LBXGH</th>\n",
       "      <th>URXUMA</th>\n",
       "      <th>URXUCR</th>\n",
       "      <th>MCQ010</th>\n",
       "      <th>MCQ160A</th>\n",
       "      <th>SMQ020</th>\n",
       "      <th>SMD030</th>\n",
       "      <th>PAQ605</th>\n",
       "      <th>PAQ620</th>\n",
       "      <th>LBXGLU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109271.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109274.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>12.8</td>\n",
       "      <td>120.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109282.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109286.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109290.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>22.4</td>\n",
       "      <td>272.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SEQN  RIAGENDR  RIDAGEYR  RIDRETH1  LBXGH  URXUMA  URXUCR  MCQ010  \\\n",
       "0  109271.0       1.0      49.0       3.0    5.6     2.4    32.0     1.0   \n",
       "1  109274.0       1.0      68.0       5.0    5.7    12.8   120.0     2.0   \n",
       "2  109282.0       1.0      76.0       3.0    5.5    16.0   192.0     2.0   \n",
       "3  109286.0       2.0      33.0       5.0    5.7     6.8    74.0     2.0   \n",
       "4  109290.0       2.0      68.0       4.0    8.4    22.4   272.0     2.0   \n",
       "\n",
       "   MCQ160A  SMQ020  SMD030  PAQ605  PAQ620  LBXGLU  \n",
       "0      1.0     1.0    18.0     2.0     1.0   103.0  \n",
       "1      1.0     2.0     NaN     1.0     1.0   154.0  \n",
       "2      2.0     1.0    18.0     2.0     2.0    95.0  \n",
       "3      2.0     2.0     NaN     2.0     2.0    92.0  \n",
       "4      1.0     2.0     NaN     2.0     1.0   106.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = [\n",
    "    'SEQN',\n",
    "    # Demographics\n",
    "    'RIAGENDR', 'RIDAGEYR', 'RIDRETH1',\n",
    "\n",
    "    # GHB\n",
    "    'LBXGH',   # Glycohemoglobin %\n",
    "\n",
    "    # ALB/CR\n",
    "    'URXUMA', 'URXUCR',  # Albumin, Creatinine in urine\n",
    "\n",
    "    # MCQ: medical condition Qs\n",
    "    'MCQ010',  # Ever told you had arthritis\n",
    "    'MCQ160A', # Ever told you had kidney disease\n",
    "\n",
    "    # SMQ: smoking\n",
    "    'SMQ020',  # Smoked at least 100 cigs\n",
    "    'SMD030',  # Smoke now?\n",
    "\n",
    "    # PAQ: physical activity\n",
    "    'PAQ605',  # Moderate activity?\n",
    "    'PAQ620',  # Vigorous activity?\n",
    "\n",
    "    # GLU\n",
    "    'LBXGLU',  # Blood glucose (mg/dL)\n",
    "]\n",
    "\n",
    "# Filter the merged dataset to only keep these\n",
    "df = df[selected_columns]\n",
    "\n",
    "print(f\"âœ… Final selected shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8167a7cf-918f-4dd7-b9c9-7c2527e38187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… After dropping missing: (1689, 14)\n"
     ]
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "print(f\"âœ… After dropping missing: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7112855-7268-4070-9ec4-0afa6dc8bcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKD\n",
      "0    1068\n",
      "1     621\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create binary target: 1 = Yes (has CKD), 0 = No\n",
    "df['CKD'] = df['MCQ160A'].apply(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "# Drop the original column as weâ€™ve used it to make the label\n",
    "df = df.drop(columns=['MCQ160A'])\n",
    "\n",
    "print(df['CKD'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79aec8f5-6457-4378-a010-377f45cd5cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:/Project + App/ALB_CR.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 1: Load ALB_CR data (if not already done)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m alb_cr \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:/Project + App/ALB_CR.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# or read_sas if in .XPT\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 2: Calculate ACR\u001b[39;00m\n\u001b[0;32m      5\u001b[0m alb_cr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACR\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (alb_cr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURXUMA\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m/\u001b[39m alb_cr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mURXUCR\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m88.4\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:/Project + App/ALB_CR.csv'"
     ]
    }
   ],
   "source": [
    "# Step 1: Load ALB_CR data (if not already done)\n",
    "alb_cr = pd.read_csv('E:/Project + App/ALB_CR.csv')  # or read_sas if in .XPT\n",
    "\n",
    "# Step 2: Calculate ACR\n",
    "alb_cr['ACR'] = (alb_cr['URXUMA'] / alb_cr['URXUCR']) * 88.4\n",
    "\n",
    "# Step 3: Define CKD based on ACR\n",
    "alb_cr['CKD'] = (alb_cr['ACR'] >= 30).astype(int)\n",
    "\n",
    "# Step 4: Check CKD distribution\n",
    "print(alb_cr['CKD'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebacc2e1-5cc3-4c6c-aa53-5315a9169614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'E:/Project + App/ALB_CR_J.XPT'\n",
    "alb_cr = pd.read_sas(file_path)\n",
    "\n",
    "alb_cr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab12720-89e8-4802-ae32-89de400bbaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alb_cr['ACR'] = (alb_cr['URXUMA'] / alb_cr['URXUCR']) * 88.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77a1d3-4e73-4f60-923a-3da98a522322",
   "metadata": {},
   "outputs": [],
   "source": [
    "alb_cr['CKD_lab'] = alb_cr['ACR'].apply(lambda x: 1 if x >= 30 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904d8e5-aad9-4ede-9481-a0581be6925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alb_cr['CKD_lab'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd71177-853d-46cc-a60a-7d9a80e897f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Keep only SEQN and CKD_lab from alb_cr\n",
    "ckd_label_df = alb_cr[['SEQN', 'CKD_lab']]\n",
    "\n",
    "# Step 2: Merge on SEQN\n",
    "final_df = pd.merge(merged_data, ckd_label_df, on='SEQN', how='inner')\n",
    "\n",
    "# Step 3: Drop any remaining missing values\n",
    "final_df = final_df.dropna()\n",
    "\n",
    "# Step 4: Check result\n",
    "print(\"Final shape after merge:\", final_df.shape)\n",
    "print(final_df['CKD_lab'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38b131-c3fc-451a-8c41-27e8ca406227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the demographic file if not already loaded\n",
    "import pandas as pd\n",
    "demo_df = pd.read_sas(\"E:/Project + App/P_DEMO.XPT\")  # adjust if file name differs\n",
    "\n",
    "# Keep only relevant features\n",
    "demo_df = demo_df[['SEQN', 'RIDAGEYR', 'RIAGENDR', 'RIDRETH3', 'DMDEDUC2', 'INDFMPIR']]\n",
    "demo_df = demo_df.rename(columns={\n",
    "    'RIDAGEYR': 'Age',\n",
    "    'RIAGENDR': 'Gender',\n",
    "    'RIDRETH3': 'Race',\n",
    "    'DMDEDUC2': 'Education',\n",
    "    'INDFMPIR': 'IncomeRatio'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259dd9a-0cb4-4148-9c92-cf7540f96db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your existing CKD-labeled dataframe\n",
    "ckd_label_df = alb_cr[['SEQN', 'CKD_lab']]\n",
    "\n",
    "# Merge demographics with CKD labels\n",
    "merged_data = pd.merge(demo_df, ckd_label_df, on='SEQN', how='inner')\n",
    "\n",
    "# Drop missing values\n",
    "merged_data = merged_data.dropna()\n",
    "\n",
    "# Check size and class balance\n",
    "print(\"Merged data shape:\", merged_data.shape)\n",
    "print(merged_data['CKD_lab'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab222d-a282-4178-b6ea-6994eddabdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many IDs are common\n",
    "common_ids = set(demo_df['SEQN']).intersection(set(alb_cr['SEQN']))\n",
    "print(\"Number of common SEQN IDs:\", len(common_ids))\n",
    "\n",
    "# Optionally view a few\n",
    "print(\"Sample common IDs:\", list(common_ids)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e305d59-74fa-4b1e-9ef7-bf39fbf905b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df['SEQN'].head()\n",
    "demo_df['SEQN'].min(), demo_df['SEQN'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152b06d5-2dca-4991-9597-8dbfef61f55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "alb_cr['SEQN'].head()\n",
    "alb_cr['SEQN'].min(), alb_cr['SEQN'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb5b3af-0a3c-488e-b360-d3dc44f74d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "alb_cr = pd.read_sas(r\"E:\\Project + App\\ALB_CR_J.XPT\")\n",
    "\n",
    "# Quick preview\n",
    "print(alb_cr[['SEQN', 'URXUMA', 'URXUCR']].head())\n",
    "print(\"SEQN range:\", alb_cr['SEQN'].min(), \"-\", alb_cr['SEQN'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743cd44-ca24-4ced-b50e-e58a77e4dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate ACR and Create CKD_lab label\n",
    "alb_cr = alb_cr.copy()\n",
    "alb_cr['ACR'] = (alb_cr['URXUMA'] / alb_cr['URXUCR']) * 100\n",
    "\n",
    "# Step 2: Apply CKD_lab label\n",
    "alb_cr['CKD_lab'] = alb_cr['ACR'].apply(lambda x: 1 if x >= 30 else 0)\n",
    "\n",
    "# Step 3: Filter relevant columns\n",
    "ckd_label_df = alb_cr[['SEQN', 'ACR', 'CKD_lab']].dropna()\n",
    "\n",
    "# Step 4: Quick summary\n",
    "print(\"CKD_lab value counts:\")\n",
    "print(ckd_label_df['CKD_lab'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72018cb0-47ae-4199-b808-4540df2adeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Features SEQN range: {final_features_df['SEQN'].min()} - {final_features_df['SEQN'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd175c5-4913-431c-89f7-40ca65537eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Merge demographic and lab data (example only)\n",
    "merged_features_df = pd.merge(demo_df, lab_df, on='SEQN', how='inner')\n",
    "\n",
    "# Add lifestyle or other datasets the same way\n",
    "merged_features_df = pd.merge(merged_features_df, diet_df, on='SEQN', how='inner')  # Optional\n",
    "\n",
    "# Assign to final_features_df for consistency\n",
    "final_features_df = merged_features_df\n",
    "\n",
    "# Sanity check SEQN range\n",
    "print(f\"Features SEQN range: {final_features_df['SEQN'].min()} - {final_features_df['SEQN'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f30368a-5608-429c-8d9e-2ded38081c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "alb_cr = pd.read_sas('ALB_CR_J.XPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2427328b-06bd-404d-ba25-8eb04b2a9829",
   "metadata": {},
   "outputs": [],
   "source": [
    "alb_cr = pd.read_sas(r'â€ªE:\\Project + App\\ALB_CR_J.xpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae50203-2150-4d2d-8f7e-749dfc6ffc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r'E:\\Project + App\\ALB_CR_J.xpt'\n",
    "print(os.path.exists(file_path))  # Should return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49516908-4a7d-4ca4-99ec-d534b3158a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-type the path manually or use raw string without hidden characters\n",
    "alb_cr = pd.read_sas(r'E:\\Project + App\\ALB_CR_J.xpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca67422-d4f5-41a0-b5c5-5d4cfbd2e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge albumin-creatinine data with CKD label dataset\n",
    "merged_df = pd.merge(CKD_lab_df, alb_cr, on='SEQN', how='inner')\n",
    "\n",
    "# Check result\n",
    "print(f\"Merged shape: {merged_df.shape}\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e02639-6227-4a1a-ae63-0cc396aba620",
   "metadata": {},
   "outputs": [],
   "source": [
    "creatinine_df = pd.read_sas(r\"E:\\Project + App\\BIOPRO_J.xpt\")  # adjust path\n",
    "print(creatinine_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ff429-ecce-467b-9f66-8c6f24d973b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load biochemistry and demographics\n",
    "biopro_df = pd.read_sas(r\"E:\\Project + App\\BIOPRO_J.xpt\")\n",
    "demo_df = pd.read_sas(r\"E:\\Project + App\\P_DEMO.xpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf870ae-dc22-4c58-8a8d-77cf46398f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Biochemistry Profile columns:\")\n",
    "print(biopro_df.columns.tolist())\n",
    "\n",
    "print(\"\\nDemographic columns:\")\n",
    "print(demo_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819e04d-b306-4238-b84b-d8d8a4b56fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge on SEQN\n",
    "df = pd.merge(biopro_df, demo_df, on='SEQN', how='inner')\n",
    "\n",
    "# Rename for clarity\n",
    "df = df.rename(columns={\n",
    "    'LBXSCR': 'Creatinine',\n",
    "    'LBXSGL': 'Glucose',\n",
    "    'LBXSCH': 'Cholesterol',\n",
    "    'LBXSUA': 'UricAcid',\n",
    "    'LBXSCK': 'CreatineKinase',\n",
    "    'RIDAGEYR': 'Age',\n",
    "    'RIAGENDR': 'Sex',\n",
    "    'RIDRETH3': 'Race'\n",
    "})\n",
    "\n",
    "# Create CKD label (custom threshold based on sex)\n",
    "def classify_ckd(row):\n",
    "    if row['Sex'] == 1:  # Male\n",
    "        return 1 if row['Creatinine'] > 1.2 else 0\n",
    "    elif row['Sex'] == 2:  # Female\n",
    "        return 1 if row['Creatinine'] > 1.0 else 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "biopro_df['CKD_lab'] = biopro_df.apply(classify_ckd, axis=1)\n",
    "\n",
    "# Drop rows with missing values in key features\n",
    "df_model = df[['Age', 'Sex', 'Race', 'Creatinine', 'Glucose', 'Cholesterol', 'UricAcid', 'CreatineKinase', 'CKD_lab']].dropna()\n",
    "\n",
    "# Check target distribution\n",
    "print(df_model['CKD_lab'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241aa7dd-c2d2-4372-b5f1-85fd111256c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Creatinine' column exists and is numeric\n",
    "def classify_ckd(row):\n",
    "    if pd.notnull(row['Creatinine']):\n",
    "        return 1 if row['Creatinine'] > 1.0 else 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply function\n",
    "df['CKD_lab'] = df.apply(classify_ckd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109030a7-1d40-493e-a1ce-d6b7962d1071",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(biopro_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905d7ac-1633-43b4-8b1b-320ab2c445c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = biopro_df.merge(demo_df[['SEQN', 'SEXN']], on='SEQN', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bc065-fa2b-4459-89b8-57a4d2304dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3204a79-c07b-4d07-9618-4175aaf945d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = biopro_df.merge(demo_df[['SEQN', 'RIAGENDR']], on='SEQN', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05484363-1ad8-403c-9a6e-2798b438fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_ckd(row):\n",
    "    if row['RIAGENDR'] == 1:  # Male\n",
    "        return 1 if row['LBXSCR'] > 1.2 else 0\n",
    "    elif row['RIAGENDR'] == 2:  # Female\n",
    "        return 1 if row['LBXSCR'] > 1.0 else 0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "merged_df['CKD_lab'] = merged_df.apply(classify_ckd, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a368f2f-aaf5-400e-9dbc-1c8909ec65a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab5ccf-ef5a-4392-94b1-ffeafde32189",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df['CKD_lab'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb13f2-93d1-44e5-b59c-ec3098fda509",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('LBXSCR' in merged_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76094de-a795-4ef8-8122-92b38aabbb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total rows:\", len(merged_df))\n",
    "print(\"Missing LBXSCR:\", merged_df['LBXSCR'].isna().sum())\n",
    "print(\"Missing RIAGENDR:\", merged_df['RIAGENDR'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5c518-1564-45be-a41b-a21671a0a2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check data types\n",
    "print(\"biopro_df SEQN type:\", biopro_df['SEQN'].dtype)\n",
    "print(\"demo_df SEQN type:\", demo_df['SEQN'].dtype)\n",
    "\n",
    "# Step 2: Standardize SEQN to int (if needed)\n",
    "biopro_df['SEQN'] = biopro_df['SEQN'].astype(int)\n",
    "demo_df['SEQN'] = demo_df['SEQN'].astype(int)\n",
    "\n",
    "# Step 3: Merge again\n",
    "merged_df = pd.merge(biopro_df, demo_df, on='SEQN', how='left')  # or 'inner'\n",
    "\n",
    "# Step 4: Confirm merge\n",
    "print(\"Merged rows:\", len(merged_df))\n",
    "print(\"Missing RIAGENDR after merge:\", merged_df['RIAGENDR'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0d3bc4-3e60-4a55-8d5c-286fb4410602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many SEQN values in common?\n",
    "common_ids = set(biopro_df['SEQN']).intersection(set(demo_df['SEQN']))\n",
    "print(\"Number of matching SEQN values:\", len(common_ids))\n",
    "\n",
    "# Also check how many total unique SEQNs in each\n",
    "print(\"Unique SEQN in biopro_df:\", biopro_df['SEQN'].nunique())\n",
    "print(\"Unique SEQN in demo_df:\", demo_df['SEQN'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c7c8a-a744-4391-8ecf-c3d6d0dadd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert SEQN to integer in both dataframes\n",
    "biopro_df['SEQN'] = biopro_df['SEQN'].astype(int)\n",
    "demo_df['SEQN'] = demo_df['SEQN'].astype(int)\n",
    "\n",
    "# Re-check overlap\n",
    "matching_seqn = set(biopro_df['SEQN']).intersection(set(demo_df['SEQN']))\n",
    "print(f\"Number of matching SEQN values after fix: {len(matching_seqn)}\")\n",
    "\n",
    "# Now try merging\n",
    "merged_df = pd.merge(biopro_df, demo_df, on='SEQN', how='left')\n",
    "\n",
    "# Validate\n",
    "print(\"Merged rows:\", len(merged_df))\n",
    "print(\"Missing RIAGENDR after merge:\", merged_df['RIAGENDR'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb431db-e834-414f-960b-b874666d6adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load SAS transport files (.xpt)\n",
    "biopro_df = pd.read_sas(r'E:\\Project + App\\BIOPRO_J.xpt', format='xport')\n",
    "demo_df = pd.read_sas(r'E:\\Project + App\\P_DEMO.xpt', format='xport')\n",
    "\n",
    "# Check the first few rows\n",
    "print(biopro_df.head())\n",
    "print(demo_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0248698-4aa2-4831-b197-b3d1169ede2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "biopro_df['SEQN'] = biopro_df['SEQN'].astype(int)\n",
    "demo_df['SEQN'] = demo_df['SEQN'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08c425-4068-4036-bcb0-27362aec2add",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_ids = set(biopro_df['SEQN']) & set(demo_df['SEQN'])\n",
    "print(f\"Number of matching SEQN values: {len(matching_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ef8cb-1f19-4ace-a13b-1c35e0d29e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_df = pd.read_sas(r\"E:\\Project + App\\BIOPRO_J.xpt\")  # Load demographics for Cycle J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fdd25-a20a-49ff-9ea3-9192b23910ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure SEQN is integer\n",
    "biopro_df['SEQN'] = biopro_df['SEQN'].astype(int)\n",
    "demo_df['SEQN'] = demo_df['SEQN'].astype(int)\n",
    "\n",
    "# Merge\n",
    "merged_df = pd.merge(biopro_df, demo_df, on='SEQN', how='inner')\n",
    "print(\"Merged rows:\", merged_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c011f313-89b7-4238-a834-a9140852e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Feature list\n",
    "selected_cols = [\n",
    "    'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'INDFMPIR', 'DMDEDUC2',\n",
    "    'LBXSCR', 'LBXGH', 'LBDGLUSI', 'LBDHDL', 'LBDLDL',\n",
    "    'LBXSATSI', 'LBXSKSI', 'LBXSBU',\n",
    "    'CKD_lab'\n",
    "]\n",
    "\n",
    "# Step 2: Subset and drop missing values\n",
    "data = merged_df[selected_cols].dropna()\n",
    "\n",
    "# Step 3: Encode target as binary\n",
    "data['CKD_lab'] = data['CKD_lab'].astype(int)\n",
    "\n",
    "# Step 4: Encode categoricals\n",
    "data['RIAGENDR'] = data['RIAGENDR'].replace({1: 'Male', 2: 'Female'})\n",
    "data['RIDRETH1'] = data['RIDRETH1'].astype(str)\n",
    "data['DMDEDUC2'] = data['DMDEDUC2'].astype(str)\n",
    "\n",
    "# One-hot encode categorical vars\n",
    "data_encoded = pd.get_dummies(data, columns=['RIAGENDR', 'RIDRETH1', 'DMDEDUC2'], drop_first=True)\n",
    "\n",
    "# Step 5: Create X and y\n",
    "X = data_encoded.drop(columns=['CKD_lab'])\n",
    "y = data_encoded['CKD_lab']\n",
    "\n",
    "# Display status\n",
    "print(f\"âœ… Final feature shape: {X.shape}\")\n",
    "print(\"âœ… CKD Class distribution:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853bfc57-f99a-4597-a013-7b4c670c3f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdddc43-283a-4ac3-bae0-3b366514c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[['LBXSCR_x', 'LBXSCR_y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf33f6f-1358-4cad-9310-3472808351d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all '_y' columns\n",
    "merged_df = merged_df.drop(columns=[col for col in merged_df.columns if col.endswith('_y')])\n",
    "\n",
    "# Rename '_x' columns to remove the suffix\n",
    "merged_df.columns = merged_df.columns.str.replace('_x$', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46ef4d-88b7-43df-8699-98bfca4c31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = [\n",
    "    'RIAGENDR', 'RIDAGEYR', 'RIDRETH1', 'INDFMPIR', 'DMDEDUC2',\n",
    "    'LBXSCR', 'LBXGH', 'LBDGLUSI', 'LBDHDL', 'LBDLDL',\n",
    "    'LBXSATSI', 'LBXSKSI', 'LBXSBU',\n",
    "    'CKD_lab'  # or whichever label youâ€™ve defined\n",
    "]\n",
    "\n",
    "data = merged_df[selected_cols].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4889cd-5f73-41ad-8405-bb8373e007c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca85f78-a00a-4530-8d82-b89e423656cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = [\n",
    "    'LBXSCR',     # Serum creatinine\n",
    "    'LBXSATSI',   # Sodium\n",
    "    'LBXSBU',     # BUN\n",
    "    'LBXSKSI',    # Potassium\n",
    "    'LBXSGL',     # Glucose\n",
    "    'LBXSCH',     # Cholesterol\n",
    "    'LBXSCA',     # Calcium\n",
    "    'LBXSUA',     # Uric acid\n",
    "    'LBXSGTSI',   # SGPT\n",
    "    'CKD_lab'     # This will be created using eGFR\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1660ba8b-8a42-477e-93ff-e74dbb645b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CKD label: if creatinine >= 1.3 mg/dL (simplified proxy), assume CKD\n",
    "merged_df['CKD_lab'] = merged_df['LBXSCR'].apply(lambda x: 1 if x >= 1.3 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a182dd5-ed30-422e-bebb-86f198dadc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_df[selected_cols].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc43a8-0204-469f-8c9b-c309dd9932e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "X = data.drop(columns='CKD_lab')\n",
    "y = data['CKD_lab']\n",
    "\n",
    "print(\"Class balance:\\n\", y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e0c24e-73e1-4f68-821d-b3ddf2a5e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns='CKD_lab')\n",
    "y = data['CKD_lab']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65612c1a-bc36-4362-b361-a5be675ab0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and label\n",
    "X = data.drop(columns='CKD_lab')\n",
    "y = data['CKD_lab']\n",
    "\n",
    "# Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b483331d-d13c-4eda-ac09-83ba3e16abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Train logistic regression\n",
    "log_reg = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = log_reg.predict(X_test_scaled)\n",
    "y_prob = log_reg.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8168dd-c30f-4ef6-b1a6-7eeae25b336a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE to training data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n",
    "y_prob_rf = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e5c1cf-7968-4b26-b068-21f4eb6669b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863d59a8-1f72-4c6b-af9a-d917d7df78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create SHAP explainer for tree-based models\n",
    "explainer = shap.TreeExplainer(rf, model_output=\"probability\")\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot summary of feature importance\n",
    "shap.summary_plot(shap_values[1], X_test_scaled, feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f6015-c213-4339-b587-20c5c9c25e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Re-wrap the scaled test set with column names\n",
    "X_test_df = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "\n",
    "# Now plot using SHAP\n",
    "shap.summary_plot(shap_values[1], X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66cef0b-ad01-42cd-b129-416279b0fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Use raw output (default), no background data needed\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "\n",
    "# Use unscaled test set for explanation\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# If X_test is a NumPy array, convert to DataFrame\n",
    "X_test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "# Plot SHAP summary for class 1 (CKD)\n",
    "shap.summary_plot(shap_values[1], X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f3170-078a-4c0c-a922-e4d311ec6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c5d21-0248-4a8c-83f6-ee0e65344abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(shap_values))          # list or np.ndarray?\n",
    "print(len(shap_values))           # should be 2 for binary classification\n",
    "print(np.array(shap_values).shape)  # will show shape of each class\n",
    "print(X_test_df.shape)           # confirm feature count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2a23be-ab3f-42f4-bc2e-83250e04e6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SHAP values for class 1 (CKD)\n",
    "shap_values_class1 = shap_values[:, :, 1]  # shape: (1180, 9)\n",
    "\n",
    "# SHAP summary plot\n",
    "shap.summary_plot(shap_values_class1, X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775dc0b0-3dd7-4294-8c70-62ffa518ff74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Save summary plot to file\n",
    "shap.summary_plot(shap_values[:, :, 1], X_test_df, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_summary_ckd.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e3cbc-7de7-42d9-9cf9-4062c93fa22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=shap_importance.values, y=shap_importance.index, hue=shap_importance.index, palette=\"viridis\", legend=False)\n",
    "plt.xlabel(\"Mean |SHAP Value|\")\n",
    "plt.title(\"Feature Importance (Mean Absolute SHAP Values)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_bar_plot_ckd.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426b3e86-bba0-44c9-ac45-e7b58165c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_single, X_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a09222-e99e-4c22-85f8-f472e58a1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a single test instance (e.g., the 10th sample)\n",
    "i = 10\n",
    "X_single = X_test_df.iloc[i:i+1]  # Keep as DataFrame for SHAP\n",
    "print(\"CKD status (actual):\", y_test[i])  # Optional: see actual label\n",
    "\n",
    "# Extract SHAP values for class 1 (CKD) only\n",
    "shap_values_single = shap_values[i, :, 1]\n",
    "\n",
    "# Display force plot\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_single, X_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12c6e11-7995-4c50-a728-660d61870a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop using .iloc to access by position\n",
    "for idx in range(len(y_test)):\n",
    "    if y_test.iloc[idx] == 1:      # access by position\n",
    "        i = idx\n",
    "        break\n",
    "\n",
    "# Select the CKD-positive sample\n",
    "X_single = X_test_df.iloc[i:i+1]                  # as DataFrame\n",
    "shap_values_single = shap_values[i, :, 1]         # SHAP for class 1 (CKD)\n",
    "\n",
    "print(f\"CKD status (actual): {y_test.iloc[i]} (Index: {i})\")\n",
    "\n",
    "# Show SHAP force plot\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[1], shap_values_single, X_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5003a6-a397-4545-99df-66a9fba8a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean absolute SHAP values for feature importance\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"Feature\": X_test_df.columns,\n",
    "    \"SHAP Importance\": np.abs(shap_values[:, :, 1]).mean(axis=0)\n",
    "}).sort_values(\"SHAP Importance\", ascending=False)\n",
    "\n",
    "print(shap_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db7eb08-05aa-4fff-a2f1-8ce47413cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"LBXSCR\", shap_values[:, :, 1], X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53aa058-5573-4d58-b1a5-e1fcfc377ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dependence plot for BUN (LBXSBU)\n",
    "shap.dependence_plot(\n",
    "    ind=\"LBXSBU\",\n",
    "    shap_values=shap_values,\n",
    "    features=X_test,\n",
    "    interaction_index=\"LBXSCR\",  # Interaction with Creatinine\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Dependence Plot: BUN (LBXSBU)\")\n",
    "plt.tight_layout()\n",
    "plt.show()=\"LBXSBU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf50e69-5b7e-4780-8769-16b05507d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dependence plot for BUN (LBXSBU)\n",
    "shap.dependence_plot(\n",
    "    ind=\"LBXSBU\",\n",
    "    shap_values=shap_values,\n",
    "    features=X_test,\n",
    "    interaction_index=\"LBXSCR\",  # Interaction with Creatinine\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Dependence Plot: BUN (LBXSBU)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e46aec-7910-478b-8be7-f943017d0198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(shap_values.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458825d3-e474-426a-b98f-03209ca9512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract SHAP values for class 1 (CKD)\n",
    "shap_values_class1 = shap_values[:, :, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3596dd-256b-4e3e-a4f2-d97464b4111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dependence plot\n",
    "shap.dependence_plot(\n",
    "    ind=\"LBXSBU\",                      # Main feature: BUN\n",
    "    shap_values=shap_values_class1,   # Use SHAP values for class 1 (CKD)\n",
    "    features=X_test,\n",
    "    interaction_index=\"LBXSCR\",       # Interacting feature: Creatinine\n",
    "    show=False\n",
    ")\n",
    "plt.title(\"SHAP Dependence Plot: BUN vs Creatinine\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75542ab0-ebb4-4905-bdde-860331404bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate and save SHAP dependence plot\n",
    "shap.dependence_plot(\n",
    "    \"LBXSBU\",             # BUN\n",
    "    shap_values[:, :, 1], # SHAP values for class 1 (CKD = 1)\n",
    "    X_test_df,\n",
    "    interaction_index=\"LBXSCR\", # Creatinine\n",
    "    show=False\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"shap_dependence_bun_vs_creatinine.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc501d-1bb4-4614-817d-7d0db4043973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data folder if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "# Save the final DataFrame as CSV\n",
    "merged_df.to_csv(\"../data/ckd_simulated_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8657e5c-c2ed-4260-a7f2-3462eccef699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_\n",
      "_4\n",
      "df\n"
     ]
    }
   ],
   "source": [
    "for var in dir():\n",
    "    if isinstance(eval(var), pd.DataFrame):\n",
    "        print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28d1fd3c-caef-4f31-984f-d467cf182bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "df.to_csv(\"../data/ckd_simulated_input.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
